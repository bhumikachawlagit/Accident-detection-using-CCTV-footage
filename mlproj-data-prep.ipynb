{"cells":[{"cell_type":"markdown","metadata":{},"source":["# 0. Imports"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-12-16T07:24:06.842595Z","iopub.status.busy":"2023-12-16T07:24:06.841753Z","iopub.status.idle":"2023-12-16T07:24:08.515609Z","shell.execute_reply":"2023-12-16T07:24:08.514297Z","shell.execute_reply.started":"2023-12-16T07:24:06.842526Z"},"trusted":true},"outputs":[],"source":["# for data handling and manipulation:\n","import pandas as pd\n","import numpy as np\n","\n","# for reading image dataset\n","import cv2\n","\n","# for os handling\n","import os\n","\n","# for dimensionality reduction\n","from sklearn.decomposition import PCA\n","from sklearn.decomposition import IncrementalPCA\n"]},{"cell_type":"markdown","metadata":{},"source":["# 1. Reading image data for accidents"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T07:48:08.173193Z","iopub.status.busy":"2023-12-15T07:48:08.172742Z","iopub.status.idle":"2023-12-15T07:48:08.623135Z","shell.execute_reply":"2023-12-15T07:48:08.622306Z","shell.execute_reply.started":"2023-12-15T07:48:08.173165Z"},"trusted":true},"outputs":[],"source":["# defining the path for accident images:\n","path_for_accident_images = \"/kaggle/input/accident-detection-from-cctv-footage/data/train/Accident\"  \n","\n","# getting  list of all images in the accident images available in the dataset\n","accident_images = os.listdir(path_for_accident_images)\n","\n","accident_images_paths = [\"/kaggle/input/accident-detection-from-cctv-footage/data/train/Accident/\" + i for i in accident_images]\n"]},{"cell_type":"markdown","metadata":{},"source":["# Viewing images"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T05:15:35.625055Z","iopub.status.busy":"2023-12-15T05:15:35.624752Z","iopub.status.idle":"2023-12-15T05:15:35.636352Z","shell.execute_reply":"2023-12-15T05:15:35.634791Z","shell.execute_reply.started":"2023-12-15T05:15:35.625028Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[{"data":{"text/plain":["\"\\nfor file in accident_images:\\n    # cv2 requires the path of the image for reading it:\\n    img_path = os.path.join(path_for_accident_images,file)\\n    \\n    # reading the image using it's path:\\n    image = cv2.imread(img_path)\\n\\n    # showing the image\\n    cv2.imshow('Image', image)\\n\\n    # making cv2 wait before closing the image, for us to press any key on the keyboard\\n    cv2.waitKey(0)\\n    \\n# destroying all windows in the end: \\ncv2.destroyAllWindows()\\n\\n\""]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# Code for seeing the training data images\n","\"\"\"\n","for file in accident_images:\n","    # cv2 requires the path of the image for reading it:\n","    img_path = os.path.join(path_for_accident_images,file)\n","    \n","    # reading the image using it's path:\n","    image = cv2.imread(img_path)\n","\n","    # showing the image\n","    cv2.imshow('Image', image)\n","\n","    # making cv2 wait before closing the image, for us to press any key on the keyboard\n","    cv2.waitKey(0)\n","    \n","# destroying all windows in the end: \n","cv2.destroyAllWindows()\n","\n","\"\"\""]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T05:15:35.640513Z","iopub.status.busy":"2023-12-15T05:15:35.639143Z","iopub.status.idle":"2023-12-15T05:15:35.662259Z","shell.execute_reply":"2023-12-15T05:15:35.660205Z","shell.execute_reply.started":"2023-12-15T05:15:35.640465Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[{"data":{"text/plain":["'\"\\nfor file in accident_images:\\n    # cv2 requires the path of the image for reading it:\\n    img_path = os.path.join(path_for_accident_images,file)\\n    \\n    # reading the image using it\\'s path:\\n    image = cv2.imread(img_path)\\n    \\n    # converting the RGB image to Grayscale:\\n    gray_image = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\\n\\n    # showing the image\\n    cv2.imshow(\\'Image\\', gray_image)\\n\\n    # making cv2 wait before closing the image, for us to press any key on the keyboard\\n    cv2.waitKey(0)\\n    \\n# destroying all windows in the end: \\ncv2.destroyAllWindows()\\n\\n'"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["# Code for seeing the training data images if converted to grayscale\n","\"\"\"\"\n","for file in accident_images:\n","    # cv2 requires the path of the image for reading it:\n","    img_path = os.path.join(path_for_accident_images,file)\n","    \n","    # reading the image using it's path:\n","    image = cv2.imread(img_path)\n","    \n","    # converting the RGB image to Grayscale:\n","    gray_image = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n","\n","    # showing the image\n","    cv2.imshow('Image', gray_image)\n","\n","    # making cv2 wait before closing the image, for us to press any key on the keyboard\n","    cv2.waitKey(0)\n","    \n","# destroying all windows in the end: \n","cv2.destroyAllWindows()\n","\n","\"\"\""]},{"cell_type":"code","execution_count":5,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2023-12-15T05:15:35.664088Z","iopub.status.busy":"2023-12-15T05:15:35.663701Z","iopub.status.idle":"2023-12-15T05:15:44.934588Z","shell.execute_reply":"2023-12-15T05:15:44.933567Z","shell.execute_reply.started":"2023-12-15T05:15:35.664057Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(576, 720, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(576, 720, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(576, 720, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(576, 720, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(576, 720, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(576, 720, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(576, 720, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n"]}],"source":["# Code for checking the dimensions of the image data\n","\n","for file in accident_images:\n","    # cv2 requires the path of the image for reading it:\n","    img_path = os.path.join(path_for_accident_images,file)\n","    \n","    # reading the image using it's path:\n","    image = cv2.imread(img_path)\n","    print(image.shape)"]},{"cell_type":"markdown","metadata":{},"source":["### It turns out, the images have different dimensions, we need to resize them to a uniform dimension, because we have to flatten them into input features for each image eventually, and images can't have different number of input features associated with them\n","\n","### We are going to upscale the smaller images using Bicubic Interpolation, because downsizing images causes a lot of loss of precious pixel data"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T05:15:44.936493Z","iopub.status.busy":"2023-12-15T05:15:44.935633Z","iopub.status.idle":"2023-12-15T05:15:51.244263Z","shell.execute_reply":"2023-12-15T05:15:51.243358Z","shell.execute_reply.started":"2023-12-15T05:15:44.936459Z"},"trusted":true},"outputs":[],"source":["# Code for resizing the smaller images and storing all the images\n","\n","gray_images = []\n","color_images = []\n","\n","for file in accident_images_paths:\n","\n","    # reading the image using it's path:\n","    color_image = cv2.imread(file)\n","\n","    # also converting it to grayscale to reduce the number of features\n","    gray_image = cv2.cvtColor(color_image,cv2.COLOR_BGR2GRAY)\n","    \n","    if color_image.shape != (720,1280,3) or gray_image.shape != (720,1280):\n","        \n","        new_height = 720\n","        new_width = 1280\n","        \n","        # resizing the images\n","        color_resized_image = cv2.resize(color_image, (new_height, new_width), interpolation = cv2.INTER_CUBIC)\n","        gray_resized_image = cv2.resize(gray_image, (new_height, new_width), interpolation = cv2.INTER_CUBIC)\n","    else:\n","        color_resized_image = color_image\n","        gray_resized_image = gray_image\n","        \n","    # flattening the image\n","    final_gray_image = gray_resized_image.flatten()\n","    final_color_image = color_resized_image.flatten()\n"," \n","    gray_images.append(final_gray_image)\n","    color_images.append(final_color_image)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T05:15:51.247542Z","iopub.status.busy":"2023-12-15T05:15:51.246304Z","iopub.status.idle":"2023-12-15T05:15:51.258684Z","shell.execute_reply":"2023-12-15T05:15:51.255818Z","shell.execute_reply.started":"2023-12-15T05:15:51.247493Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["####################\n"]}],"source":["# Code for checking the dimensions of the image data\n","\n","for image in gray_images:\n","    \n","    # print the shape of the image\n","    if image.shape[0] != new_height*new_width:\n","        print(image.shape)\n","\n","\n","print('#'*20)\n","\n","for image in color_images:\n","    \n","    # print the shape of the image\n","    if image.shape[0] != new_height*new_width*3:\n","        print(image.shape)"]},{"cell_type":"markdown","metadata":{},"source":["### Hence, all images are now of the same dimension : (2764800,) : Means 1-D with 2764800 elements for colored images and 921600 for gray images"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T05:15:51.261013Z","iopub.status.busy":"2023-12-15T05:15:51.260449Z","iopub.status.idle":"2023-12-15T05:15:51.269943Z","shell.execute_reply":"2023-12-15T05:15:51.268666Z","shell.execute_reply.started":"2023-12-15T05:15:51.260972Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(369, 369)"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["len(gray_images), len(color_images)   # as expected 369 accident images for training"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T05:15:51.272206Z","iopub.status.busy":"2023-12-15T05:15:51.271782Z","iopub.status.idle":"2023-12-15T05:15:51.279052Z","shell.execute_reply":"2023-12-15T05:15:51.277444Z","shell.execute_reply.started":"2023-12-15T05:15:51.272101Z"},"trusted":true},"outputs":[],"source":["# creating the corresponding y_labels\n","y = [1]*len(accident_images)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T05:15:51.283703Z","iopub.status.busy":"2023-12-15T05:15:51.283306Z","iopub.status.idle":"2023-12-15T05:15:51.296198Z","shell.execute_reply":"2023-12-15T05:15:51.294879Z","shell.execute_reply.started":"2023-12-15T05:15:51.283663Z"},"trusted":true},"outputs":[{"data":{"text/plain":["[1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1]"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["y"]},{"cell_type":"markdown","metadata":{},"source":["# 2. Reading image data for non-accidents"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T05:15:51.298233Z","iopub.status.busy":"2023-12-15T05:15:51.297896Z","iopub.status.idle":"2023-12-15T05:15:51.685488Z","shell.execute_reply":"2023-12-15T05:15:51.683895Z","shell.execute_reply.started":"2023-12-15T05:15:51.298204Z"},"trusted":true},"outputs":[],"source":["# defining the path for accident images:\n","path_for_non_accident_images = \"/kaggle/input/accident-detection-from-cctv-footage/data/train/Non Accident\"\n","\n","# getting  list of all images in the accident images available in the dataset\n","non_accident_images = os.listdir(path_for_non_accident_images)\n","\n","non_accident_images_paths = [\"/kaggle/input/accident-detection-from-cctv-footage/data/train/Non Accident/\" + i for i in non_accident_images]"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T05:15:51.688786Z","iopub.status.busy":"2023-12-15T05:15:51.688214Z","iopub.status.idle":"2023-12-15T05:16:01.874033Z","shell.execute_reply":"2023-12-15T05:16:01.872795Z","shell.execute_reply.started":"2023-12-15T05:15:51.688708Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(576, 720, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(576, 720, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(576, 720, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(576, 720, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(576, 720, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(576, 720, 3)\n","(576, 720, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(576, 720, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(576, 720, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(576, 720, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(576, 720, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(576, 720, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(576, 720, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(576, 720, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(576, 720, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(576, 720, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(576, 720, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(576, 720, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n"]}],"source":["# Code for checking the dimensions of the image data\n","\n","for file in non_accident_images_paths:\n","    \n","    # reading the image using it's path:\n","    image = cv2.imread(file)\n","    \n","    # print the dimensions of the image\n","    print(image.shape)\n","    "]},{"cell_type":"markdown","metadata":{},"source":["### Here too, we can see, some images in the beginning are smaller in size"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T05:16:01.875935Z","iopub.status.busy":"2023-12-15T05:16:01.875503Z","iopub.status.idle":"2023-12-15T05:16:08.898290Z","shell.execute_reply":"2023-12-15T05:16:08.896864Z","shell.execute_reply.started":"2023-12-15T05:16:01.875898Z"},"trusted":true},"outputs":[],"source":["# Code for resizing the smaller images and storing all the images\n","\n","\n","for file in non_accident_images_paths:\n","    \n","    # reading the image using it's path:\n","    color_image = cv2.imread(file)\n","\n","    # also converting it to grayscale to reduce the number of features\n","    gray_image = cv2.cvtColor(color_image,cv2.COLOR_BGR2GRAY)\n","    \n","    if color_image.shape != (720,1280,3) or gray_image.shape != (720,1280):\n","        \n","        new_height = 720\n","        new_width = 1280\n","        \n","        # resizing the images\n","        color_resized_image = cv2.resize(color_image, (new_height, new_width), interpolation = cv2.INTER_CUBIC)\n","        gray_resized_image = cv2.resize(gray_image, (new_height, new_width), interpolation = cv2.INTER_CUBIC)\n","    else:\n","        color_resized_image = color_image\n","        gray_resized_image = gray_image   \n","    \n","    # flattening the image\n","    final_gray_image = gray_resized_image.flatten()\n","    final_color_image = color_resized_image.flatten()\n","   \n","    gray_images.append(final_gray_image)\n","    color_images.append(final_color_image)\n"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T05:16:08.900131Z","iopub.status.busy":"2023-12-15T05:16:08.899833Z","iopub.status.idle":"2023-12-15T05:16:08.907802Z","shell.execute_reply":"2023-12-15T05:16:08.906527Z","shell.execute_reply.started":"2023-12-15T05:16:08.900094Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["####################\n"]}],"source":["# Code for checking the dimensions of the image data\n","\n","for image in gray_images:\n","    \n","    # print the shape of the image\n","    if image.shape[0] != new_height*new_width:\n","        print(image.shape)\n","\n","\n","print('#'*20)\n","\n","for image in color_images:\n","    \n","    # print the shape of the image\n","    if image.shape[0] != new_height*new_width*3:\n","      print(image.shape)"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T05:16:08.913046Z","iopub.status.busy":"2023-12-15T05:16:08.909128Z","iopub.status.idle":"2023-12-15T05:16:08.934745Z","shell.execute_reply":"2023-12-15T05:16:08.933143Z","shell.execute_reply.started":"2023-12-15T05:16:08.912997Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(791, 791)"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["len(gray_images), len(color_images)   # as expected: accident + non_accident images = 369 + 422 = 791"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T05:16:08.937234Z","iopub.status.busy":"2023-12-15T05:16:08.936710Z","iopub.status.idle":"2023-12-15T05:16:08.945711Z","shell.execute_reply":"2023-12-15T05:16:08.944173Z","shell.execute_reply.started":"2023-12-15T05:16:08.937191Z"},"trusted":true},"outputs":[],"source":["# extending y to add labels for the images added to `images`\n","y.extend([0]*len(non_accident_images))"]},{"cell_type":"code","execution_count":17,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2023-12-15T05:16:08.947253Z","iopub.status.busy":"2023-12-15T05:16:08.946872Z","iopub.status.idle":"2023-12-15T05:16:08.971819Z","shell.execute_reply":"2023-12-15T05:16:08.970214Z","shell.execute_reply.started":"2023-12-15T05:16:08.947216Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"data":{"text/plain":["[1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0]"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["y"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T05:16:08.974082Z","iopub.status.busy":"2023-12-15T05:16:08.973492Z","iopub.status.idle":"2023-12-15T05:16:09.737808Z","shell.execute_reply":"2023-12-15T05:16:09.735776Z","shell.execute_reply.started":"2023-12-15T05:16:08.974025Z"},"trusted":true},"outputs":[],"source":["# converting the list of images to a numpy array\n","color_images = np.array(color_images)\n","\n","gray_images = np.array(gray_images)"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T05:16:09.740904Z","iopub.status.busy":"2023-12-15T05:16:09.740501Z","iopub.status.idle":"2023-12-15T05:16:09.747221Z","shell.execute_reply":"2023-12-15T05:16:09.745632Z","shell.execute_reply.started":"2023-12-15T05:16:09.740871Z"},"trusted":true},"outputs":[],"source":["# converting labels array to numpy as well:\n","y = np.array(y)"]},{"cell_type":"markdown","metadata":{},"source":["### So, now our `gray images` contains the images data converted to grayscale and `color images` contains image data for all colored images, for all accident and non-accident images, flattened into it's rows and `y` contains the corresponding labels for these images.\n","\n","### 0: Non_accident image, 1: Accident image"]},{"cell_type":"markdown","metadata":{},"source":["### Thankfully, only a few images were smaller in size than the other images, hence, we had to interpolate pixels and make only a few images larger than they originally were"]},{"cell_type":"markdown","metadata":{},"source":["# 3. Image Pre-processing "]},{"cell_type":"markdown","metadata":{},"source":["Not aware of any techniques as of now."]},{"cell_type":"markdown","metadata":{},"source":["## 3.1 Dimensionality Reduction  "]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T05:16:09.749805Z","iopub.status.busy":"2023-12-15T05:16:09.749314Z","iopub.status.idle":"2023-12-15T05:16:09.761641Z","shell.execute_reply":"2023-12-15T05:16:09.760881Z","shell.execute_reply.started":"2023-12-15T05:16:09.749762Z"},"trusted":true},"outputs":[{"data":{"text/plain":["array([[169, 171, 172, ...,  84,  85,  85],\n","       [ 81,  62,  20, ...,  51,  52,  52],\n","       [ 86,  90,  83, ..., 103, 103, 103],\n","       ...,\n","       [173, 174, 170, ...,  93,  92,  93],\n","       [ 65,  68,  64, ...,  25,  27,  29],\n","       [ 58,  78,  85, ..., 101, 101, 101]], dtype=uint8)"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["gray_images "]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T05:16:09.763258Z","iopub.status.busy":"2023-12-15T05:16:09.762892Z","iopub.status.idle":"2023-12-15T05:16:09.774241Z","shell.execute_reply":"2023-12-15T05:16:09.772533Z","shell.execute_reply.started":"2023-12-15T05:16:09.763226Z"},"trusted":true},"outputs":[{"data":{"text/plain":["array([[174, 174, 156, ...,  90,  85,  84],\n","       [ 93,  91,  57, ...,  20,  65,  38],\n","       [ 72,  77, 108, ..., 110, 105,  96],\n","       ...,\n","       [184, 174, 167, ..., 102,  91,  94],\n","       [ 72,  60,  72, ...,  17,  31,  30],\n","       [ 65,  56,  59, ..., 105, 102,  98]], dtype=uint8)"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["color_images"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T05:16:09.776306Z","iopub.status.busy":"2023-12-15T05:16:09.775906Z","iopub.status.idle":"2023-12-15T05:16:09.786940Z","shell.execute_reply":"2023-12-15T05:16:09.785853Z","shell.execute_reply.started":"2023-12-15T05:16:09.776275Z"},"trusted":true},"outputs":[{"data":{"text/plain":["((791, 921600), (791, 2764800))"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["gray_images.shape, color_images.shape"]},{"cell_type":"markdown","metadata":{},"source":["### Couldn't run PCA on colored images without encountering memory error"]},{"cell_type":"markdown","metadata":{},"source":["### Trying to retain 95% of the variation of the image data"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T05:16:09.789182Z","iopub.status.busy":"2023-12-15T05:16:09.788815Z","iopub.status.idle":"2023-12-15T05:16:09.798670Z","shell.execute_reply":"2023-12-15T05:16:09.797793Z","shell.execute_reply.started":"2023-12-15T05:16:09.789142Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'\\npca = PCA(n_components = 0.95)\\nX_train = pca.fit_transform(gray_images)\\n\\nX_train.shape\\n'"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["\"\"\"\n","pca = PCA(n_components = 0.95)\n","X_train = pca.fit_transform(gray_images)\n","\n","X_train.shape\n","\"\"\""]},{"cell_type":"markdown","metadata":{},"source":["### Can retain a maximum of 98 features, because features in train, test and val have to be equal and <= min(samples, features) of train, test and val"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T05:16:09.800212Z","iopub.status.busy":"2023-12-15T05:16:09.799906Z","iopub.status.idle":"2023-12-15T05:17:14.985835Z","shell.execute_reply":"2023-12-15T05:17:14.984103Z","shell.execute_reply.started":"2023-12-15T05:16:09.800185Z"},"trusted":true},"outputs":[],"source":["pca_gray = PCA(n_components = 98)\n","X_train_gray = pca_gray.fit_transform(gray_images)"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T05:17:14.988201Z","iopub.status.busy":"2023-12-15T05:17:14.987804Z","iopub.status.idle":"2023-12-15T05:17:14.997020Z","shell.execute_reply":"2023-12-15T05:17:14.995695Z","shell.execute_reply.started":"2023-12-15T05:17:14.988160Z"},"trusted":true},"outputs":[{"data":{"text/plain":["0.9292593067123059"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["sum(pca_gray.explained_variance_ratio_)"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T05:17:14.999258Z","iopub.status.busy":"2023-12-15T05:17:14.998814Z","iopub.status.idle":"2023-12-15T05:20:24.412144Z","shell.execute_reply":"2023-12-15T05:20:24.410535Z","shell.execute_reply.started":"2023-12-15T05:17:14.999219Z"},"trusted":true},"outputs":[],"source":["pca_color = PCA(n_components = 98)\n","X_train_color = pca_color.fit_transform(color_images)"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T05:20:24.417762Z","iopub.status.busy":"2023-12-15T05:20:24.417316Z","iopub.status.idle":"2023-12-15T05:20:24.424593Z","shell.execute_reply":"2023-12-15T05:20:24.423526Z","shell.execute_reply.started":"2023-12-15T05:20:24.417702Z"},"trusted":true},"outputs":[{"data":{"text/plain":["0.9312746419282848"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["sum(pca_color.explained_variance_ratio_)"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T05:20:24.432540Z","iopub.status.busy":"2023-12-15T05:20:24.432127Z","iopub.status.idle":"2023-12-15T05:20:24.442229Z","shell.execute_reply":"2023-12-15T05:20:24.441144Z","shell.execute_reply.started":"2023-12-15T05:20:24.432508Z"},"trusted":true},"outputs":[{"data":{"text/plain":["array([[-12387.48180764,  19559.86453961, -29390.00937941, ...,\n","          -241.11917869,   -659.73537099,     78.59143171],\n","       [ 22399.09574135,   2037.98593839,  16219.81113874, ...,\n","          -107.45869357,    132.91009494,     53.0107237 ],\n","       [ -5646.40808565,  40678.56124055, -11914.08422211, ...,\n","           775.28970294,    124.72548977,  -1796.03317354],\n","       ...,\n","       [    91.27973281,  -9431.64303006,  12869.39982115, ...,\n","          1093.3746155 ,   -809.75672208,  -1536.37282289],\n","       [ -3122.27585681,   1590.58283503,   4102.97630181, ...,\n","          -318.24861263,   -754.89811785,   -797.17956191],\n","       [ -6839.49068472, -15148.62082936,   2621.33031367, ...,\n","          -540.79295623,    244.59213871,  -1554.48627677]])"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["X_train_gray"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T05:20:24.443865Z","iopub.status.busy":"2023-12-15T05:20:24.443491Z","iopub.status.idle":"2023-12-15T05:20:24.454644Z","shell.execute_reply":"2023-12-15T05:20:24.453639Z","shell.execute_reply.started":"2023-12-15T05:20:24.443833Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(791, 98)"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["X_train_gray.shape"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T05:20:24.456461Z","iopub.status.busy":"2023-12-15T05:20:24.456149Z","iopub.status.idle":"2023-12-15T05:20:24.471333Z","shell.execute_reply":"2023-12-15T05:20:24.470329Z","shell.execute_reply.started":"2023-12-15T05:20:24.456433Z"},"trusted":true},"outputs":[{"data":{"text/plain":["array([[-1.48807674e+04,  3.37702825e+04, -5.31024815e+04, ...,\n","        -7.47567203e+02,  5.87897070e+02, -8.00290756e+02],\n","       [ 4.18582083e+04,  4.95716525e+03,  3.36635969e+04, ...,\n","        -2.59856132e+02,  1.35249325e+02,  4.25838921e+01],\n","       [-4.46680240e+03,  6.65670682e+04, -2.08697992e+04, ...,\n","        -1.62509969e+03,  3.32420358e+03, -3.63190540e+03],\n","       ...,\n","       [-2.82446173e+03, -1.79458451e+04,  1.98483342e+04, ...,\n","        -3.55968070e+02,  1.81237722e+03, -2.65393149e+02],\n","       [-6.24969305e+03,  3.62751822e+03,  7.12923753e+03, ...,\n","        -2.78458102e+03, -6.20031916e+02,  9.68769106e+02],\n","       [-1.40664790e+04, -2.51845757e+04,  6.43196741e+03, ...,\n","         4.81291406e+02,  4.91481336e+02,  1.50974867e+03]])"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["X_train_color"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T05:20:24.474291Z","iopub.status.busy":"2023-12-15T05:20:24.473333Z","iopub.status.idle":"2023-12-15T05:20:24.484939Z","shell.execute_reply":"2023-12-15T05:20:24.483545Z","shell.execute_reply.started":"2023-12-15T05:20:24.474247Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(791, 98)"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["X_train_color.shape"]},{"cell_type":"markdown","metadata":{},"source":["### Moving on to the task of preparing validation data now after saving the train data"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T05:20:24.488232Z","iopub.status.busy":"2023-12-15T05:20:24.486349Z","iopub.status.idle":"2023-12-15T05:20:24.666914Z","shell.execute_reply":"2023-12-15T05:20:24.665238Z","shell.execute_reply.started":"2023-12-15T05:20:24.488173Z"},"trusted":true},"outputs":[],"source":["pd.DataFrame(X_train_gray).to_csv('X_train_gray.csv')"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T05:20:24.669293Z","iopub.status.busy":"2023-12-15T05:20:24.668876Z","iopub.status.idle":"2023-12-15T05:20:24.754668Z","shell.execute_reply":"2023-12-15T05:20:24.753165Z","shell.execute_reply.started":"2023-12-15T05:20:24.669250Z"},"trusted":true},"outputs":[],"source":["pd.DataFrame(X_train_color).to_csv('X_train_color.csv')"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T05:20:24.756812Z","iopub.status.busy":"2023-12-15T05:20:24.756345Z","iopub.status.idle":"2023-12-15T05:20:24.764377Z","shell.execute_reply":"2023-12-15T05:20:24.763271Z","shell.execute_reply.started":"2023-12-15T05:20:24.756774Z"},"trusted":true},"outputs":[],"source":["pd.DataFrame(y).to_csv('y_train.csv')"]},{"cell_type":"markdown","metadata":{},"source":["# 4. Reading image data for accidents (Validation set)"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T05:20:24.766340Z","iopub.status.busy":"2023-12-15T05:20:24.765940Z","iopub.status.idle":"2023-12-15T05:20:24.813684Z","shell.execute_reply":"2023-12-15T05:20:24.812425Z","shell.execute_reply.started":"2023-12-15T05:20:24.766308Z"},"trusted":true},"outputs":[],"source":["# defining the path for accident images:\n","path_for_accident_images = \"/kaggle/input/accident-detection-from-cctv-footage/data/val/Accident\"  \n","\n","# getting  list of all images in the accident images available in the dataset\n","accident_images = os.listdir(path_for_accident_images)\n","\n","accident_images_paths = [\"/kaggle/input/accident-detection-from-cctv-footage/data/val/Accident/\" + i for i in accident_images]\n"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T05:20:24.816416Z","iopub.status.busy":"2023-12-15T05:20:24.815250Z","iopub.status.idle":"2023-12-15T05:20:25.932658Z","shell.execute_reply":"2023-12-15T05:20:25.930894Z","shell.execute_reply.started":"2023-12-15T05:20:24.816376Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(576, 720, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(576, 720, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n"]}],"source":["# Code for checking the dimensions of the image data\n","\n","for file in accident_images_paths:\n","\n","    # reading the image using it's path:\n","    image = cv2.imread(file)\n","    print(image.shape)"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T05:20:25.934395Z","iopub.status.busy":"2023-12-15T05:20:25.934058Z","iopub.status.idle":"2023-12-15T05:20:26.594809Z","shell.execute_reply":"2023-12-15T05:20:26.594057Z","shell.execute_reply.started":"2023-12-15T05:20:25.934362Z"},"trusted":true},"outputs":[],"source":["# Code for resizing the smaller images and storing all the images\n","\n","gray_images = []\n","color_images = []\n","\n","for file in accident_images:\n","\n","    # cv2 requires the path of the image for reading it:\n","    img_path = os.path.join(path_for_accident_images,file)\n","    \n","    # reading the image using it's path:\n","    color_image = cv2.imread(img_path)\n","\n","    # also converting it to grayscale to reduce the number of features\n","    gray_image = cv2.cvtColor(color_image,cv2.COLOR_BGR2GRAY)\n","    \n","    if color_image.shape != (720,1280,3) or gray_image.shape != (720,1280):\n","        \n","        new_height = 720\n","        new_width = 1280\n","        \n","        # resizing the images\n","        color_resized_image = cv2.resize(color_image, (new_height, new_width), interpolation = cv2.INTER_CUBIC)\n","        gray_resized_image = cv2.resize(gray_image, (new_height, new_width), interpolation = cv2.INTER_CUBIC)\n","    \n","    else:\n","        color_resized_image = color_image\n","        gray_resized_image = gray_image    \n","    \n","    # flattening the image\n","    final_gray_image = gray_resized_image.flatten().T\n","    final_color_image = color_resized_image.flatten().T\n","    \n","    gray_images.append(final_gray_image)\n","    color_images.append(final_color_image)\n"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T05:20:26.596626Z","iopub.status.busy":"2023-12-15T05:20:26.596051Z","iopub.status.idle":"2023-12-15T05:20:26.604256Z","shell.execute_reply":"2023-12-15T05:20:26.602883Z","shell.execute_reply.started":"2023-12-15T05:20:26.596592Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["####################\n"]}],"source":["# Code for checking the dimensions of the image data\n","\n","for image in gray_images:\n","    \n","    # print the shape of the image\n","    if image.shape[0] != new_height*new_width:\n","        print(image.shape)\n","\n","\n","print('#'*20)\n","\n","for image in color_images:\n","    \n","    # print the shape of the image\n","    if image.shape[0] != new_height*new_width*3:\n","        print(image.shape)"]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T05:20:26.606007Z","iopub.status.busy":"2023-12-15T05:20:26.605443Z","iopub.status.idle":"2023-12-15T05:20:26.623680Z","shell.execute_reply":"2023-12-15T05:20:26.622308Z","shell.execute_reply.started":"2023-12-15T05:20:26.605970Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(46, 46)"]},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":["len(gray_images), len(color_images) "]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T05:20:26.625388Z","iopub.status.busy":"2023-12-15T05:20:26.625010Z","iopub.status.idle":"2023-12-15T05:20:26.632278Z","shell.execute_reply":"2023-12-15T05:20:26.630600Z","shell.execute_reply.started":"2023-12-15T05:20:26.625333Z"},"trusted":true},"outputs":[],"source":["y = [1]*len(accident_images)"]},{"cell_type":"code","execution_count":41,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T05:20:26.635247Z","iopub.status.busy":"2023-12-15T05:20:26.634047Z","iopub.status.idle":"2023-12-15T05:20:26.648530Z","shell.execute_reply":"2023-12-15T05:20:26.646847Z","shell.execute_reply.started":"2023-12-15T05:20:26.635206Z"},"trusted":true},"outputs":[{"data":{"text/plain":["[1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1]"]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["y"]},{"cell_type":"markdown","metadata":{},"source":["# 5. Reading image data for non-accidents (Validation set)"]},{"cell_type":"code","execution_count":42,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T05:20:26.650354Z","iopub.status.busy":"2023-12-15T05:20:26.649936Z","iopub.status.idle":"2023-12-15T05:20:26.680272Z","shell.execute_reply":"2023-12-15T05:20:26.679177Z","shell.execute_reply.started":"2023-12-15T05:20:26.650319Z"},"trusted":true},"outputs":[],"source":["# defining the path for accident images:\n","path_for_non_accident_images = \"/kaggle/input/accident-detection-from-cctv-footage/data/val/Non Accident\"\n","\n","# getting  list of all images in the accident images available in the dataset\n","non_accident_images = os.listdir(path_for_non_accident_images)\n","\n","non_accident_images_paths = [\"/kaggle/input/accident-detection-from-cctv-footage/data/val/Non Accident/\" + i for i in non_accident_images]\n"]},{"cell_type":"code","execution_count":43,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T05:20:26.685011Z","iopub.status.busy":"2023-12-15T05:20:26.684541Z","iopub.status.idle":"2023-12-15T05:20:27.946082Z","shell.execute_reply":"2023-12-15T05:20:27.944758Z","shell.execute_reply.started":"2023-12-15T05:20:26.684978Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(576, 720, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(576, 720, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(576, 720, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n"]}],"source":["# Code for checking the dimensions of the image data\n","\n","for file in non_accident_images_paths:\n","    \n","    # reading the image using it's path:\n","    image = cv2.imread(file)\n","    \n","    # print the dimensions of the image\n","    print(image.shape)"]},{"cell_type":"code","execution_count":44,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T05:20:27.951219Z","iopub.status.busy":"2023-12-15T05:20:27.950840Z","iopub.status.idle":"2023-12-15T05:20:28.793601Z","shell.execute_reply":"2023-12-15T05:20:28.792181Z","shell.execute_reply.started":"2023-12-15T05:20:27.951189Z"},"trusted":true},"outputs":[],"source":["# Code for resizing the smaller images and storing all the images\n","\n","\n","for file in non_accident_images:\n","\n","    # cv2 requires the path of the image for reading it:\n","    img_path = os.path.join(path_for_non_accident_images,file)\n","    \n","    # reading the image using it's path:\n","    color_image = cv2.imread(img_path)\n","\n","    # also converting it to grayscale to reduce the number of features\n","    gray_image = cv2.cvtColor(color_image,cv2.COLOR_BGR2GRAY)\n","    \n","    if color_image.shape != (720,1280,3) or gray_image.shape != (720,1280,3):\n","        \n","        new_height = 720\n","        new_width = 1280\n","        \n","        # resizing the images\n","        color_resized_image = cv2.resize(color_image, (new_height, new_width), interpolation = cv2.INTER_CUBIC)\n","        gray_resized_image = cv2.resize(gray_image, (new_height, new_width), interpolation = cv2.INTER_CUBIC)\n","    \n","    else:\n","        color_resized_image = color_image\n","        gray_resized_image = gray_image\n","    \n","    # flattening the image\n","    final_gray_image = gray_resized_image.flatten()\n","    final_color_image = color_resized_image.flatten()\n","    \n","    gray_images.append(final_gray_image)\n","    color_images.append(final_color_image)\n"]},{"cell_type":"code","execution_count":45,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T05:20:28.795749Z","iopub.status.busy":"2023-12-15T05:20:28.795207Z","iopub.status.idle":"2023-12-15T05:20:28.802766Z","shell.execute_reply":"2023-12-15T05:20:28.801593Z","shell.execute_reply.started":"2023-12-15T05:20:28.795683Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["####################\n"]}],"source":["# Code for checking the dimensions of the image data\n","\n","for image in gray_images:\n","    \n","    # print the shape of the image\n","    if image.shape[0] != new_height*new_width:\n","        print(image.shape)\n","\n","\n","print('#'*20)\n","\n","for image in color_images:\n","    \n","    # print the shape of the image\n","    if image.shape[0] != new_height*new_width*3:\n","        print(image.shape)"]},{"cell_type":"code","execution_count":46,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T05:20:28.804631Z","iopub.status.busy":"2023-12-15T05:20:28.804249Z","iopub.status.idle":"2023-12-15T05:20:28.818877Z","shell.execute_reply":"2023-12-15T05:20:28.817879Z","shell.execute_reply.started":"2023-12-15T05:20:28.804600Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(98, 98)"]},"execution_count":46,"metadata":{},"output_type":"execute_result"}],"source":["len(gray_images), len(color_images)"]},{"cell_type":"code","execution_count":47,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T05:20:28.820443Z","iopub.status.busy":"2023-12-15T05:20:28.820188Z","iopub.status.idle":"2023-12-15T05:20:28.828520Z","shell.execute_reply":"2023-12-15T05:20:28.827295Z","shell.execute_reply.started":"2023-12-15T05:20:28.820421Z"},"trusted":true},"outputs":[],"source":["# extending y to add labels for the images added to `images`\n","y.extend([0]*len(non_accident_images))"]},{"cell_type":"code","execution_count":48,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T05:20:28.831542Z","iopub.status.busy":"2023-12-15T05:20:28.831072Z","iopub.status.idle":"2023-12-15T05:20:28.842701Z","shell.execute_reply":"2023-12-15T05:20:28.841673Z","shell.execute_reply.started":"2023-12-15T05:20:28.831505Z"},"trusted":true},"outputs":[{"data":{"text/plain":["[1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0]"]},"execution_count":48,"metadata":{},"output_type":"execute_result"}],"source":["y"]},{"cell_type":"code","execution_count":49,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T05:20:28.844393Z","iopub.status.busy":"2023-12-15T05:20:28.844110Z","iopub.status.idle":"2023-12-15T05:20:28.895426Z","shell.execute_reply":"2023-12-15T05:20:28.892682Z","shell.execute_reply.started":"2023-12-15T05:20:28.844369Z"},"trusted":true},"outputs":[],"source":["# converting the list of images to a numpy array\n","color_images = np.array(color_images)\n","\n","gray_images = np.array(gray_images)"]},{"cell_type":"code","execution_count":50,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T05:20:28.898666Z","iopub.status.busy":"2023-12-15T05:20:28.898233Z","iopub.status.idle":"2023-12-15T05:20:28.905350Z","shell.execute_reply":"2023-12-15T05:20:28.904075Z","shell.execute_reply.started":"2023-12-15T05:20:28.898630Z"},"trusted":true},"outputs":[],"source":["# converting labels array to numpy as well:\n","y = np.array(y)"]},{"cell_type":"markdown","metadata":{},"source":["## Applying PCA to reduce dimension"]},{"cell_type":"code","execution_count":51,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T05:20:28.908671Z","iopub.status.busy":"2023-12-15T05:20:28.908186Z","iopub.status.idle":"2023-12-15T05:20:29.862516Z","shell.execute_reply":"2023-12-15T05:20:29.861681Z","shell.execute_reply.started":"2023-12-15T05:20:28.908632Z"},"trusted":true},"outputs":[],"source":["# To retain 98 features, to match the no. of features of the training set\n","X_val_gray = pca_gray.transform(gray_images)"]},{"cell_type":"code","execution_count":52,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T05:20:29.864510Z","iopub.status.busy":"2023-12-15T05:20:29.863937Z","iopub.status.idle":"2023-12-15T05:20:32.871609Z","shell.execute_reply":"2023-12-15T05:20:32.870213Z","shell.execute_reply.started":"2023-12-15T05:20:29.864479Z"},"trusted":true},"outputs":[],"source":["X_val_color = pca_color.transform(color_images)"]},{"cell_type":"code","execution_count":53,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T05:20:32.874577Z","iopub.status.busy":"2023-12-15T05:20:32.873341Z","iopub.status.idle":"2023-12-15T05:20:32.880620Z","shell.execute_reply":"2023-12-15T05:20:32.879934Z","shell.execute_reply.started":"2023-12-15T05:20:32.874536Z"},"trusted":true},"outputs":[{"data":{"text/plain":["((98, 98), (98, 98))"]},"execution_count":53,"metadata":{},"output_type":"execute_result"}],"source":["X_val_gray.shape, X_val_color.shape"]},{"cell_type":"code","execution_count":54,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T05:20:32.882938Z","iopub.status.busy":"2023-12-15T05:20:32.882124Z","iopub.status.idle":"2023-12-15T05:20:32.909356Z","shell.execute_reply":"2023-12-15T05:20:32.908506Z","shell.execute_reply.started":"2023-12-15T05:20:32.882906Z"},"trusted":true},"outputs":[],"source":["pd.DataFrame(X_val_gray).to_csv('X_val_gray.csv')"]},{"cell_type":"code","execution_count":55,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T05:20:32.911590Z","iopub.status.busy":"2023-12-15T05:20:32.910990Z","iopub.status.idle":"2023-12-15T05:20:32.940007Z","shell.execute_reply":"2023-12-15T05:20:32.939084Z","shell.execute_reply.started":"2023-12-15T05:20:32.911555Z"},"trusted":true},"outputs":[],"source":["pd.DataFrame(X_val_color).to_csv('X_val_color.csv')"]},{"cell_type":"code","execution_count":56,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T05:20:32.942514Z","iopub.status.busy":"2023-12-15T05:20:32.941826Z","iopub.status.idle":"2023-12-15T05:20:32.951529Z","shell.execute_reply":"2023-12-15T05:20:32.949819Z","shell.execute_reply.started":"2023-12-15T05:20:32.942475Z"},"trusted":true},"outputs":[],"source":["pd.DataFrame(y).to_csv('y_val.csv')"]},{"cell_type":"markdown","metadata":{},"source":["### Moving on to the task of preparing test data now"]},{"cell_type":"markdown","metadata":{},"source":["# 7. Reading image data for accidents (Test set)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-12-16T07:24:45.124951Z","iopub.status.busy":"2023-12-16T07:24:45.124062Z","iopub.status.idle":"2023-12-16T07:24:45.146228Z","shell.execute_reply":"2023-12-16T07:24:45.144654Z","shell.execute_reply.started":"2023-12-16T07:24:45.124899Z"},"trusted":true},"outputs":[],"source":["# defining the path for accident images:\n","path_for_accident_images = \"/kaggle/input/accident-detection-from-cctv-footage/data/test/Accident\" \n","\n","# getting  list of all images in the accident images available in the dataset\n","accident_images = os.listdir(path_for_accident_images)\n","\n","accident_images_paths = [\"/kaggle/input/accident-detection-from-cctv-footage/data/test/Accident/\" + i for i in accident_images]\n"]},{"cell_type":"code","execution_count":10,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2023-12-16T07:24:48.581121Z","iopub.status.busy":"2023-12-16T07:24:48.580661Z","iopub.status.idle":"2023-12-16T07:24:49.761776Z","shell.execute_reply":"2023-12-16T07:24:49.760509Z","shell.execute_reply.started":"2023-12-16T07:24:48.581080Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(576, 720, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n"]}],"source":["# Code for checking the dimensions of the image data\n","\n","for file in accident_images_paths:\n","    \n","    # reading the image using it's path:\n","    image = cv2.imread(file)\n","    print(image.shape)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-12-16T07:24:53.126279Z","iopub.status.busy":"2023-12-16T07:24:53.125539Z","iopub.status.idle":"2023-12-16T07:24:54.168800Z","shell.execute_reply":"2023-12-16T07:24:54.166211Z","shell.execute_reply.started":"2023-12-16T07:24:53.126232Z"},"trusted":true},"outputs":[],"source":["# Code for resizing the smaller images and storing all the images\n","\n","gray_images = []\n","color_images = []\n","\n","for file in accident_images_paths:\n","\n","    # reading the image using it's path:\n","    color_image = cv2.imread(file)\n","\n","    # also converting it to grayscale to reduce the number of features\n","    gray_image = cv2.cvtColor(color_image,cv2.COLOR_BGR2GRAY)\n","    \n","    if color_image.shape != (720,1280,3) or gray_image.shape != (720,1280):\n","        \n","        new_height = 720\n","        new_width = 1280\n","        \n","        # resizing the images\n","        color_resized_image = cv2.resize(color_image, (new_height, new_width), interpolation = cv2.INTER_CUBIC)\n","        gray_resized_image = cv2.resize(gray_image, (new_height, new_width), interpolation = cv2.INTER_CUBIC)\n","    \n","    else:\n","        color_resized_image = color_image\n","        gray_resized_image = gray_image\n","    \n","    # flattening the image\n","    final_gray_image = gray_resized_image.flatten().T\n","    final_color_image = color_resized_image.flatten().T\n","    \n","    gray_images.append(final_gray_image)\n","    color_images.append(final_color_image)\n"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-12-16T07:24:55.389833Z","iopub.status.busy":"2023-12-16T07:24:55.388836Z","iopub.status.idle":"2023-12-16T07:24:55.398742Z","shell.execute_reply":"2023-12-16T07:24:55.397242Z","shell.execute_reply.started":"2023-12-16T07:24:55.389786Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["####################\n"]}],"source":["# Code for checking the dimensions of the image data\n","\n","for image in gray_images:\n","    \n","    # print the shape of the image\n","    if image.shape[0] != new_height*new_width:\n","        print(image.shape)\n","\n","\n","print('#'*20)\n","\n","for image in color_images:\n","    \n","    # print the shape of the image\n","    if image.shape[0] != new_height*new_width*3:\n","        print(image.shape)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-12-16T07:24:56.563419Z","iopub.status.busy":"2023-12-16T07:24:56.562013Z","iopub.status.idle":"2023-12-16T07:24:56.575106Z","shell.execute_reply":"2023-12-16T07:24:56.573530Z","shell.execute_reply.started":"2023-12-16T07:24:56.563361Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(47, 47)"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["len(gray_images), len(color_images) "]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-12-16T07:24:59.012882Z","iopub.status.busy":"2023-12-16T07:24:59.012451Z","iopub.status.idle":"2023-12-16T07:24:59.019691Z","shell.execute_reply":"2023-12-16T07:24:59.018096Z","shell.execute_reply.started":"2023-12-16T07:24:59.012847Z"},"trusted":true},"outputs":[],"source":["y = [1]*len(accident_images)"]},{"cell_type":"code","execution_count":15,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2023-12-16T07:25:02.339189Z","iopub.status.busy":"2023-12-16T07:25:02.338624Z","iopub.status.idle":"2023-12-16T07:25:02.349651Z","shell.execute_reply":"2023-12-16T07:25:02.347822Z","shell.execute_reply.started":"2023-12-16T07:25:02.339132Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"data":{"text/plain":["[1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1]"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["y"]},{"cell_type":"markdown","metadata":{},"source":["# 7. Reading image data for non-accidents (Test set)"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-12-16T07:25:07.416214Z","iopub.status.busy":"2023-12-16T07:25:07.415671Z","iopub.status.idle":"2023-12-16T07:25:07.425950Z","shell.execute_reply":"2023-12-16T07:25:07.424209Z","shell.execute_reply.started":"2023-12-16T07:25:07.416168Z"},"trusted":true},"outputs":[],"source":["# defining the path for accident images:\n","path_for_non_accident_images = \"/kaggle/input/accident-detection-from-cctv-footage/data/test/Non Accident\" \n","\n","# getting  list of all images in the accident images available in the dataset\n","non_accident_images = os.listdir(path_for_non_accident_images)\n","\n","non_accident_images_paths = [\"/kaggle/input/accident-detection-from-cctv-footage/data/test/Non Accident/\" + i for i in non_accident_images]\n"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-12-16T07:25:10.692807Z","iopub.status.busy":"2023-12-16T07:25:10.692255Z","iopub.status.idle":"2023-12-16T07:25:10.699386Z","shell.execute_reply":"2023-12-16T07:25:10.698213Z","shell.execute_reply.started":"2023-12-16T07:25:10.692765Z"},"trusted":true},"outputs":[],"source":["non_accident_images_paths.remove('/kaggle/input/accident-detection-from-cctv-footage/data/test/Non Accident/Pictures - Shortcut.lnk')"]},{"cell_type":"code","execution_count":18,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2023-12-16T07:25:12.502754Z","iopub.status.busy":"2023-12-16T07:25:12.502034Z","iopub.status.idle":"2023-12-16T07:25:13.369738Z","shell.execute_reply":"2023-12-16T07:25:13.368213Z","shell.execute_reply.started":"2023-12-16T07:25:12.502684Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(576, 720, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n","(720, 1280, 3)\n"]}],"source":["# Code for checking the dimensions of the image data\n","\n","for file in non_accident_images_paths:\n","   \n","    # reading the image using it's path:\n","    image = cv2.imread(file)\n","    \n","    # print the dimensions of the image\n","    print(image.shape)"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-12-16T07:25:15.444880Z","iopub.status.busy":"2023-12-16T07:25:15.444438Z","iopub.status.idle":"2023-12-16T07:25:16.749043Z","shell.execute_reply":"2023-12-16T07:25:16.747719Z","shell.execute_reply.started":"2023-12-16T07:25:15.444844Z"},"trusted":true},"outputs":[],"source":["# Code for resizing the smaller images and storing all the images\n","\n","for file in non_accident_images_paths:\n","\n","    # reading the image using it's path:\n","    color_image = cv2.imread(file)\n","\n","    # also converting it to grayscale to reduce the number of features\n","    gray_image = cv2.cvtColor(color_image,cv2.COLOR_BGR2GRAY)\n","    \n","    if color_image.shape != (720,1280,3) or gray_image.shape != (720,1280):\n","        \n","        new_height = 720\n","        new_width = 1280\n","        \n","        # resizing the images\n","        color_resized_image = cv2.resize(color_image, (new_height, new_width), interpolation = cv2.INTER_CUBIC)\n","        gray_resized_image = cv2.resize(gray_image, (new_height, new_width), interpolation = cv2.INTER_CUBIC)\n","    \n","    else:\n","        color_resized_image = color_image\n","        gray_resized_image = gray_image\n","    \n","    # flattening the image\n","    final_gray_image = gray_resized_image.flatten()\n","    final_color_image = color_resized_image.flatten()\n","    \n","    gray_images.append(final_gray_image)\n","    color_images.append(final_color_image)\n"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2023-12-16T07:25:17.740522Z","iopub.status.busy":"2023-12-16T07:25:17.740044Z","iopub.status.idle":"2023-12-16T07:25:17.749770Z","shell.execute_reply":"2023-12-16T07:25:17.748139Z","shell.execute_reply.started":"2023-12-16T07:25:17.740485Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["####################\n"]}],"source":["# Code for checking the dimensions of the image data\n","\n","for image in gray_images:\n","    \n","    # print the shape of the image\n","    if image.shape[0] != new_height*new_width:\n","        print(image.shape)\n","\n","\n","print('#'*20)\n","\n","for image in color_images:\n","    \n","    # print the shape of the image\n","    if image.shape[0] != new_height*new_width*3:\n","        print(image.shape)"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2023-12-16T07:25:19.992569Z","iopub.status.busy":"2023-12-16T07:25:19.991681Z","iopub.status.idle":"2023-12-16T07:25:19.999589Z","shell.execute_reply":"2023-12-16T07:25:19.998294Z","shell.execute_reply.started":"2023-12-16T07:25:19.992530Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(100, 100)"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["len(gray_images), len(color_images)"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2023-12-16T07:25:21.428181Z","iopub.status.busy":"2023-12-16T07:25:21.427705Z","iopub.status.idle":"2023-12-16T07:25:21.434843Z","shell.execute_reply":"2023-12-16T07:25:21.433386Z","shell.execute_reply.started":"2023-12-16T07:25:21.428122Z"},"trusted":true},"outputs":[],"source":["# extending y to add labels for the images added to `images`\n","y.extend([0]*len(non_accident_images_paths))"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2023-12-16T07:25:24.557737Z","iopub.status.busy":"2023-12-16T07:25:24.557268Z","iopub.status.idle":"2023-12-16T07:25:24.832170Z","shell.execute_reply":"2023-12-16T07:25:24.830944Z","shell.execute_reply.started":"2023-12-16T07:25:24.557702Z"},"trusted":true},"outputs":[],"source":["# converting the list of images to a numpy array\n","color_images = np.array(color_images)\n","\n","gray_images = np.array(gray_images)"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2023-12-16T07:25:25.922329Z","iopub.status.busy":"2023-12-16T07:25:25.921744Z","iopub.status.idle":"2023-12-16T07:25:25.928703Z","shell.execute_reply":"2023-12-16T07:25:25.927322Z","shell.execute_reply.started":"2023-12-16T07:25:25.922283Z"},"trusted":true},"outputs":[],"source":["# converting labels array to numpy as well:\n","y = np.array(y)"]},{"cell_type":"code","execution_count":25,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2023-12-16T07:25:28.050130Z","iopub.status.busy":"2023-12-16T07:25:28.049565Z","iopub.status.idle":"2023-12-16T07:25:28.090097Z","shell.execute_reply":"2023-12-16T07:25:28.088726Z","shell.execute_reply.started":"2023-12-16T07:25:28.050089Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"ename":"NameError","evalue":"name 'pca_gray' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[25], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# To retain 98 features, to match the no. of features of the training set\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m X_test_gray \u001b[38;5;241m=\u001b[39m \u001b[43mpca_gray\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(gray_images)\n","\u001b[0;31mNameError\u001b[0m: name 'pca_gray' is not defined"]}],"source":["# To retain 98 features, to match the no. of features of the training set\n","X_test_gray = pca_gray.transform(gray_images)"]},{"cell_type":"code","execution_count":74,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T05:20:37.895590Z","iopub.status.busy":"2023-12-15T05:20:37.895098Z","iopub.status.idle":"2023-12-15T05:20:40.822401Z","shell.execute_reply":"2023-12-15T05:20:40.821539Z","shell.execute_reply.started":"2023-12-15T05:20:37.895547Z"},"trusted":true},"outputs":[],"source":["X_test_color = pca_color.transform(color_images)"]},{"cell_type":"code","execution_count":75,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T05:20:40.824436Z","iopub.status.busy":"2023-12-15T05:20:40.823860Z","iopub.status.idle":"2023-12-15T05:20:40.830102Z","shell.execute_reply":"2023-12-15T05:20:40.829394Z","shell.execute_reply.started":"2023-12-15T05:20:40.824400Z"},"trusted":true},"outputs":[{"data":{"text/plain":["((100, 98), (100, 98))"]},"execution_count":75,"metadata":{},"output_type":"execute_result"}],"source":["X_test_gray.shape, X_test_color.shape"]},{"cell_type":"code","execution_count":76,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T05:20:40.832122Z","iopub.status.busy":"2023-12-15T05:20:40.831528Z","iopub.status.idle":"2023-12-15T05:20:40.862697Z","shell.execute_reply":"2023-12-15T05:20:40.861741Z","shell.execute_reply.started":"2023-12-15T05:20:40.832090Z"},"trusted":true},"outputs":[],"source":["pd.DataFrame(X_test_gray).to_csv('X_test_gray.csv')"]},{"cell_type":"code","execution_count":77,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T05:20:40.865329Z","iopub.status.busy":"2023-12-15T05:20:40.864560Z","iopub.status.idle":"2023-12-15T05:20:40.891293Z","shell.execute_reply":"2023-12-15T05:20:40.890221Z","shell.execute_reply.started":"2023-12-15T05:20:40.865277Z"},"trusted":true},"outputs":[],"source":["pd.DataFrame(X_test_color).to_csv('X_test_color.csv')"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2023-12-16T07:25:35.732323Z","iopub.status.busy":"2023-12-16T07:25:35.731834Z","iopub.status.idle":"2023-12-16T07:25:35.752703Z","shell.execute_reply":"2023-12-16T07:25:35.751653Z","shell.execute_reply.started":"2023-12-16T07:25:35.732287Z"},"trusted":true},"outputs":[],"source":["pd.DataFrame(y).to_csv('y_test.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["t1 = pd.read_csv('X_train_gray.csv').drop(columns = ['Unnamed: 0'], axis = 1)\n","t1.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["t2 = pd.read_csv('X_val_gray.csv').drop(columns = ['Unnamed: 0'], axis = 1)\n","t2.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["t3 = pd.concat([t1,t2], axis = 0)\n","t3"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["t4 = pd.read_csv('y_train.csv').drop(columns = ['Unnamed: 0'], axis = 1)\n","t5 = pd.read_csv('y_val.csv').drop(columns = ['Unnamed: 0'], axis = 1)\n","\n","t6 = pd.concat([t4,t5], axis = 0)\n","t6.columns = ['label']\n","t6"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pd.concat([t3,t6], axis = 1).to_csv('X_train_gray_final.csv')"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":804753,"sourceId":1379553,"sourceType":"datasetVersion"}],"dockerImageVersionId":30626,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"}},"nbformat":4,"nbformat_minor":4}
